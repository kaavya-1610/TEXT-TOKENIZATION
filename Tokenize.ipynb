{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"Attention is all you need\"\n",
        "sentence = \"I went to the river bank\""
      ],
      "metadata": {
        "id": "cUI7GoGDZb_d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding"
      ],
      "metadata": {
        "id": "NnCNjtOHZjHJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the sentence"
      ],
      "metadata": {
        "id": "bJjiFTO9Z_xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec9eb83a",
        "outputId": "2c6d3bc7-4a27-46f1-cd75-bdf63bd6464c"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer() # Initialize the tokenizer\n",
        "\n",
        "tokenizer.fit_on_texts([sentence]) # Fit the tokenizer on the sentence\n",
        "\n",
        "word_sequence = tokenizer.texts_to_sequences([sentence]) # Convert the sentence to a sequence of integers\n",
        "print(f\"Original sentence: {sentence}\")\n",
        "print(f\"Tokenized sequence: {word_sequence}\")\n",
        "print(f\"Word index: {tokenizer.word_index}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: I went to the river bank\n",
            "Tokenized sequence: [[1, 2, 3, 4, 5, 6]]\n",
            "Word index: {'i': 1, 'went': 2, 'to': 3, 'the': 4, 'river': 5, 'bank': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of tokenized sentence\n",
        "print(f\"Shape of word_sequence: ({len(word_sequence)}, {len(word_sequence[0])})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37EYpuX6aYli",
        "outputId": "2e0cd007-4b75-41a4-fbfe-c7dee049777a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of word_sequence: (1, 6)\n"
          ]
        }
      ]
    }
  ]
}